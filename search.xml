<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>无人驾驶麻省理工04讲</title>
      <link href="/2019/01/12/%E6%97%A0%E4%BA%BA%E9%A9%BE%E9%A9%B6%E9%BA%BB%E7%9C%81%E7%90%86%E5%B7%A504%E8%AE%B2/"/>
      <url>/2019/01/12/%E6%97%A0%E4%BA%BA%E9%A9%BE%E9%A9%B6%E9%BA%BB%E7%9C%81%E7%90%86%E5%B7%A504%E8%AE%B2/</url>
      
        <content type="html"><![CDATA[<p>相关资料打包链接: <a href="https://whuteducn-my.sharepoint.com/:b:/g/personal/220077_whut_edu_cn/Ea5iXqDY4Q5Og-Io6nAyUAYBM4ByRP4tgk2RIkq79QRLPg?e=JdssEk" target="_blank" rel="noopener">麻省理工自动驾驶 MIT 6.S094第四讲</a><br>bilibili: <a href="https://www.bilibili.com/video/av23594594/?p=4" target="_blank" rel="noopener">麻省理工自动驾驶 MIT 6.S094第四讲</a></p><h1 id="计算机视觉"><a href="#计算机视觉" class="headerlink" title="计算机视觉"></a>计算机视觉</h1><h2 id="写在前言：最近博客没怎么更新，“万事开头难，中间难，结尾难”，这个趋势可不好，嗯，要引以为戒。“行百里者半于九十”，与诸君共勉！"><a href="#写在前言：最近博客没怎么更新，“万事开头难，中间难，结尾难”，这个趋势可不好，嗯，要引以为戒。“行百里者半于九十”，与诸君共勉！" class="headerlink" title="写在前言：最近博客没怎么更新，“万事开头难，中间难，结尾难”，这个趋势可不好，嗯，要引以为戒。“行百里者半于九十”，与诸君共勉！"></a>写在前言：最近博客没怎么更新，“万事开头难，中间难，结尾难”，这个趋势可不好，嗯，要引以为戒。“行百里者半于九十”，与诸君共勉！</h2><h2 id="数据集建立（以ImageNet为例）"><a href="#数据集建立（以ImageNet为例）" class="headerlink" title="数据集建立（以ImageNet为例）"></a>数据集建立（以ImageNet为例）</h2><p>一谈到神经网络或者深度学习，网上有很多关于这方面的资料介绍，不胜枚举。其中，关于计算机视觉的深度学习方法，基本都是以斯坦福大学李飞飞教授的课程cs231n为代表。<br><img src="/2019/01/12/无人驾驶麻省理工04讲/TIM截图20190112183632.png" alt=""><br>该图片引自斯坦福CS231n课程<br>课程直达链接：<a href="https://www.bilibili.com/video/av13260183?from=search&amp;seid=11756757080254052141" target="_blank" rel="noopener">斯坦福2017季CS231n深度视觉识别课程视频</a><br>在这里，我想分享的则是这样一个观点：对于基于图像的神经网络模型，先决条件需要建立一个数量庞大的数据集。<br><img src="/2019/01/12/无人驾驶麻省理工04讲/TIM截图20190112183305.png" alt=""><br>李飞飞在该演讲中介绍，基于传统的机器学习方法，无法更加准确、深入的教会计算机理解图片，为此他们发起了一个图片收集项目，全球数以万计的参与者为这个项目提供了丰富的图片资料，这也是后来我们熟知的ImageNet数据集。这个数据集完成后，李飞飞教授根据这个项目完成了很多惊人的成果，这也就是一开始我所强调的建立庞大数据集的必要性。<br>同样的，在MIT无人驾驶项目中，他们也同样开展了很多的实验数据收集，从而建立一个庞大的数据集，基于这些数据，得到的各种研究成果才会更加的可信。<br><img src="/2019/01/12/无人驾驶麻省理工04讲/TIM截图20190112183846.png" alt=""><br>麻省理工老师实测收集数据<br>那么又来了一个问题，我们为什么要花费庞大的精力去建设这么一个庞大的类似于数据库项目？这个根本原因其实就是取决于我们的数学工具手段。我们在机器学习或者深度学习的过程中可以发现，我们处理很多计算问题时，往往采取的是数理统计的思想方法，虽然计算式各不相同，但是基本思想并没有跳出这个藩篱。对于真实情况的认知，我们往往采取样本估计的方法更加容易实现，特别是很多无法用数学物理方程去描述的问题，采取经验公式的思路往往是行之有效的。<br><img src="/2019/01/12/无人驾驶麻省理工04讲/TIM截图20190112184203.png" alt=""><br>贝叶斯公式</p><h2 id="图像欺骗问题"><a href="#图像欺骗问题" class="headerlink" title="图像欺骗问题"></a>图像欺骗问题</h2><p>图像欺骗问题其实是一个非常值得思考的问题，在我的理解中，这其实是对于一个“环境”的分析问题。计算机是依赖于模型去完成对环境的认知，所以如果模型没有考虑到环境的复杂多样性，就会造成很大的认知失误。<br><img src="/2019/01/12/无人驾驶麻省理工04讲/153957300758908100_a580x330.jpg" alt=""><br>亚马逊公司曾经开发一个人工智能招聘系统，但是被爆出该系统歧视女性<br>对于PPT中提到的伪装成猴子的图片（P14），有很多专家提出了很多解决办法，如图像分割的方法（P41)，因为机器总是在很小的区域能够识别出猫还是猴子，只要设置优先级就可以了。但是人类识别图像问题并不完全依赖于理性认知，也有感性认知，这也就是有专家学者在SRGAN算法得到的结论：人类更加青睐于纹理边缘特征而不是像素点分布。前面所提到的基本都是按照机器理解的像素方法，由此可见在计算机视觉问题上，教会机器理解图片，首先要做到的便是设计者提高自身对于“环境”的理解深度，而这对于模型设计的好坏是非常有必要的。<br><img src="/2019/01/12/无人驾驶麻省理工04讲/TIM截图20190112184611.png" alt=""><br>SRGAN算法：人类更加青睐于纹理边缘特征而不是像素点分布</p><h2 id="卷积计算只用于图像特征问题"><a href="#卷积计算只用于图像特征问题" class="headerlink" title="卷积计算只用于图像特征问题"></a>卷积计算只用于图像特征问题</h2><p>这个问题曾经困扰了我很久，在我学习的过程中，更多接触练习的都是卷积神经网络，去各种网站论坛公布的开源代码，发现能够实现的大型网络模型也就卷积神经网络（CNN）居多。但是这并不是说深度学习只有卷积神经网络，而我陷入这一尴尬的境地，主要是能够供我们学习的公共数据集也就是MNIST、ImageNet等常见的图像数据集，别的工程领域方面提供的数据集作为案例推荐入门的并不多。<br><img src="/2019/01/12/无人驾驶麻省理工04讲/TIM截图20190112185307.png" alt=""><br>神经网络模型大致一览<br>详细参考链接：<a href="https://blog.csdn.net/qq_35082030/article/details/73368962" target="_blank" rel="noopener">不同模型特点总结</a></p>]]></content>
      
      
      
    </entry>
    
    <entry>
      <title>无人驾驶麻省理工03讲</title>
      <link href="/2018/12/15/%E6%97%A0%E4%BA%BA%E9%A9%BE%E9%A9%B6%E9%BA%BB%E7%9C%81%E7%90%86%E5%B7%A503%E8%AE%B2/"/>
      <url>/2018/12/15/%E6%97%A0%E4%BA%BA%E9%A9%BE%E9%A9%B6%E9%BA%BB%E7%9C%81%E7%90%86%E5%B7%A503%E8%AE%B2/</url>
      
        <content type="html"><![CDATA[<p>相关资料打包链接: <a href="https://whuteducn-my.sharepoint.com/:f:/g/personal/220077_whut_edu_cn/Es2eM_taTLZFkwlT-hbnkXABGafyJ10B19kd1Ltqijg9xA?e=dFowgK" target="_blank" rel="noopener">麻省理工自动驾驶 MIT 6.S094第三讲</a><br>bilibili: <a href="https://www.bilibili.com/video/av23594594?p=3" target="_blank" rel="noopener">麻省理工自动驾驶 MIT 6.S094第三讲</a></p><h1 id="深度增强学习"><a href="#深度增强学习" class="headerlink" title="深度增强学习"></a>深度增强学习</h1><p>先放出无人驾驶的框架图<br><img src="/2018/12/15/无人驾驶麻省理工03讲/TIM截图20181215201122.png" alt=""><br>从图上可以看出，深度增强学习是通过动作、反馈的奖励机制来进行网络模型的建立，在某种意义上，传感器的好坏直接决定了后面的工作质量，但是这一讲假定传感器是理想的，重点研究深度增强在模型中的运用。</p><h2 id="深度增强学习案例解说"><a href="#深度增强学习案例解说" class="headerlink" title="深度增强学习案例解说"></a>深度增强学习案例解说</h2><p>P7主要是对图像、声音、行为的识别进行分析对比。以鸭子为例，提取鸭子的图像特征（边缘检测）和声音特征（共振峰）是容易的，因为只需要考察简单的行为特征，但是对于复杂的行为特征提取就困难了，因为会游泳的不仅仅是鸭子。P8机器人的增强学习，通过训练搬箱子的过程，让机器人更加熟练的搬运箱子，这个方法的主要优点就是利用机器人具有不知疲倦的功能，能够很好的解决一些单调重复性的工作。</p><p>P20有一个实例没见过，我画出了其示意图。<br><img src="/2018/12/15/无人驾驶麻省理工03讲/TIM图片20181215203428.jpg" alt=""></p><p>P23老师还是挺贴心的，给出了马尔科夫随机分布的一个应用例子。<br><img src="/2018/12/15/无人驾驶麻省理工03讲/TIM截图20181215203743.png" alt=""></p><p>总结一下，对于深度学习也好，增强学习也罢，都是基于贝叶斯先验分布的统计思想，同时还利用马尔科夫随机分布的原理，很好解决状态随着时间的变化而改变的问题（不懂的同学可以参考一下《随机过程》、《数理统计》的相关章节）</p><h2 id="DeepTraffic仿真交通模型"><a href="#DeepTraffic仿真交通模型" class="headerlink" title="DeepTraffic仿真交通模型"></a>DeepTraffic仿真交通模型</h2><p>这个是本节的重点。P15交通仿真模型，P16给了相关的链接，code亲测挂了，大家可以搜一下老师的GitHub用户名：lexfridman。P57至P83给出了该仿真交通模型的详细操作介绍，值得注意的是，部分功能只开放给MIT 学生使用。下面放出paper阅读笔记（食用方法：下载电子版论文后，直接翻译你感兴趣的段落即可）<br><img src="/2018/12/15/无人驾驶麻省理工03讲/DeepTraffic解读.png" alt=""><br><a href="https://selfdrivingcars.mit.edu/deeptraffic" target="_blank" rel="noopener">DeepTraffic链接</a></p><h2 id="网络模型理论部分"><a href="#网络模型理论部分" class="headerlink" title="网络模型理论部分"></a>网络模型理论部分</h2><p>这一部分偏向学术了，从简单理想模型开始分析（P25至P32机器人在房间里移动），然后进行数学推导（P36数值迭代，P45DQN算法），到仿真环境工作讲解，以及其中的细节部分讨论（P53蒙特卡罗）。整个过程主要是解决计划和动作的问题，采取奖赏的机制，即要求最大化奖赏，每一步的移动都会影响奖赏，然后通过深度学习去实现这个最佳策略。</p>]]></content>
      
      
      
    </entry>
    
    <entry>
      <title>无人驾驶麻省理工01讲</title>
      <link href="/2018/12/09/%E6%97%A0%E4%BA%BA%E9%A9%BE%E9%A9%B6%E9%BA%BB%E7%9C%81%E7%90%86%E5%B7%A501%E8%AE%B2/"/>
      <url>/2018/12/09/%E6%97%A0%E4%BA%BA%E9%A9%BE%E9%A9%B6%E9%BA%BB%E7%9C%81%E7%90%86%E5%B7%A501%E8%AE%B2/</url>
      
        <content type="html"><![CDATA[<p>PDF链接: <a href="https://whuteducn-my.sharepoint.com/:b:/g/personal/220077_whut_edu_cn/EUUMsVDo9yJAg9bWfz40jQsBuXFY13DTisylqQDg1nwyUQ?e=EGdbDD" target="_blank" rel="noopener">麻省理工自动驾驶 MIT 6.S094第一讲</a><br>bilibili: <a href="https://www.bilibili.com/video/av23594594" target="_blank" rel="noopener">麻省理工自动驾驶 MIT 6.S094第一讲</a></p><h1 id="写在前言：最近在学习麻省理工自动驾驶课程，本人在学习视频的同时写了一点学习笔记，有需要的童鞋可以参考一下。"><a href="#写在前言：最近在学习麻省理工自动驾驶课程，本人在学习视频的同时写了一点学习笔记，有需要的童鞋可以参考一下。" class="headerlink" title="写在前言：最近在学习麻省理工自动驾驶课程，本人在学习视频的同时写了一点学习笔记，有需要的童鞋可以参考一下。"></a>写在前言：最近在学习麻省理工自动驾驶课程，本人在学习视频的同时写了一点学习笔记，有需要的童鞋可以参考一下。</h1><h2 id="（1）P15对于同一个问题的简单表达，如P16对于笛卡尔坐标系的分类，可以通过坐标变换在极坐标系中表达"><a href="#（1）P15对于同一个问题的简单表达，如P16对于笛卡尔坐标系的分类，可以通过坐标变换在极坐标系中表达" class="headerlink" title="（1）P15对于同一个问题的简单表达，如P16对于笛卡尔坐标系的分类，可以通过坐标变换在极坐标系中表达"></a>（1）P15对于同一个问题的简单表达，如P16对于笛卡尔坐标系的分类，可以通过坐标变换在极坐标系中表达</h2><p>我觉得这一页写的非常好，在具体分析问题时，我们都是尽可能的把复杂问题简单化，视频中老师演示了日心说和地心说的例子，同时也展示了笛卡尔坐标系的平面变换。<br><img src="/2018/12/09/无人驾驶麻省理工01讲/TIM截图20181209134754.jpg" alt=""><br><a href="http://www.365yg.com/i6632871765829747203/#mid=1619346472494083" target="_blank" rel="noopener">日心说和地心说</a><br><img src="/2018/12/09/无人驾驶麻省理工01讲/Draw a line to separate the green triangles and blue circles.png" alt=""><br>笛卡尔坐标系的平面变换</p><h2 id="（2）P22卷积计算的表达"><a href="#（2）P22卷积计算的表达" class="headerlink" title="（2）P22卷积计算的表达"></a>（2）P22卷积计算的表达</h2><p>在实际神经网络中，我们面临的往往是一个“黑匣子”，即当下流行的各种训练框架，如TensorFlow、Pytorch、Keras等，都是基于封装好的接口。因此我每次和别人讲解卷积计算感觉特费劲，这个是我见过目前最好的例子了。<img src="/2018/12/09/无人驾驶麻省理工01讲/TIM截图20181209134955.jpg" alt=""><br><a href="http://www.365yg.com/i6632863431642841613/#mid=1619346472494083" target="_blank" rel="noopener">3D视频演示</a></p><h2 id="（3）P24神经网络的演示"><a href="#（3）P24神经网络的演示" class="headerlink" title="（3）P24神经网络的演示"></a>（3）P24神经网络的演示</h2><p>这个可以作为童鞋们写PPT的一大利器啊，我是不会网页的动画扣取。<img src="/2018/12/09/无人驾驶麻省理工01讲/TIM截图20181209135406.jpg" alt=""><br><a href="https://appliedgo.net/perceptron/" target="_blank" rel="noopener">神经网络激活</a></p><h2 id="（4）P30深度增强学习的演示"><a href="#（4）P30深度增强学习的演示" class="headerlink" title="（4）P30深度增强学习的演示"></a>（4）P30深度增强学习的演示</h2><p>其实增强学习当下已经研究的非常火热，这个实例其实也一般。<img src="/2018/12/09/无人驾驶麻省理工01讲/TIM截图20181209135136.jpg" alt=""><br><a href="http://www.365yg.com/i6632863436051055118/#mid=1619346472494083" target="_blank" rel="noopener">增强学习</a></p><h2 id="（5）P38、P39、P40梯度典型问题"><a href="#（5）P38、P39、P40梯度典型问题" class="headerlink" title="（5）P38、P39、P40梯度典型问题"></a>（5）P38、P39、P40梯度典型问题</h2><p>如上所说，目前流行的深度学习框架只提供了很少的训练评估参数，但是对于研究神经网络具体的训练问题时，如梯度消失或者梯度死亡等常见的现象，我们只能是尽可能的调取其中可提供的参数进行观察，这几页很好的解决了我对梯度问题难以理解的痛点。<br><img src="/2018/12/09/无人驾驶麻省理工01讲/TIM截图20181209141147.jpg" alt=""><br><a href="http://www.365yg.com/i6632871778764997134/#mid=1619346472494083" target="_blank" rel="noopener">梯度问题01</a><br><a href="http://www.365yg.com/i6632871782967689735/#mid=1619346472494083" target="_blank" rel="noopener">梯度问题02</a><br><img src="/2018/12/09/无人驾驶麻省理工01讲/Dying ReLUs.png" alt=""></p><h2 id="（6）P44正则化防止过拟合的一种方法dropout"><a href="#（6）P44正则化防止过拟合的一种方法dropout" class="headerlink" title="（6）P44正则化防止过拟合的一种方法dropout"></a>（6）P44正则化防止过拟合的一种方法dropout</h2><p>这个方法我目前还没有接触，可能是我撸的代码不够多吧，先Mark一下。<img src="/2018/12/09/无人驾驶麻省理工01讲/TIM截图20181209135303.jpg" alt=""><br><a href="http://www.365yg.com/i6632871774423876109/#mid=1619346472494083" target="_blank" rel="noopener">正则化dropout</a></p><h2 id="（7）P46网站推荐"><a href="#（7）P46网站推荐" class="headerlink" title="（7）P46网站推荐"></a>（7）P46网站推荐</h2><p>很有趣的一个网站，可以帮助大家直观理解神经网络的操作流程。<img src="/2018/12/09/无人驾驶麻省理工01讲/TIM截图20181209135406.jpg" alt=""><br><a href="http://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=circle&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=4,2&amp;seed=0.23279&amp;showTestData=false&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false" target="_blank" rel="noopener">神经网络的演示</a></p><h2 id="（8）P57图片分割分类"><a href="#（8）P57图片分割分类" class="headerlink" title="（8）P57图片分割分类"></a>（8）P57图片分割分类</h2><p>这个感觉有点像U-net网络啊，不过又有点区别，这个侧重于提取更多的特征，很不错的思路。<img src="/2018/12/09/无人驾驶麻省理工01讲/Cover.png" alt=""><br><a href="https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner&#39;s-Guide-To-Understanding-Convolutional-Neural-Networks/" target="_blank" rel="noopener">图片分类</a></p><h2 id="（9）P61背景移除"><a href="#（9）P61背景移除" class="headerlink" title="（9）P61背景移除"></a>（9）P61背景移除</h2><p>没试过这个操作，先放出链接吧。<img src="/2018/12/09/无人驾驶麻省理工01讲/0_33XKEatpsF875NCc.jpg" alt=""><br><a href="https://towardsdatascience.com/background-removal-with-deep-learning-c4f2104b3157" target="_blank" rel="noopener">背景移除</a></p><h2 id="（10）P71AlphaGo-Zero"><a href="#（10）P71AlphaGo-Zero" class="headerlink" title="（10）P71AlphaGo Zero"></a>（10）P71AlphaGo Zero</h2><p>大名鼎鼎的AlphaGo 啊，不过这个应该是变种版，增强学习现在都脱离经验的学习了，厉害。<img src="/2018/12/09/无人驾驶麻省理工01讲/TIM截图20181209135646.jpg" alt=""><br><a href="http://www.365yg.com/i6632871770376372743/#mid=1619346472494083" target="_blank" rel="noopener">AlphaGo Zero</a></p><h2 id="（11）P73奖励游戏"><a href="#（11）P73奖励游戏" class="headerlink" title="（11）P73奖励游戏"></a>（11）P73奖励游戏</h2><p>坦白的说，这个游戏没看懂，不知道讲课老师怎么会迷恋上这种游戏。<img src="/2018/12/09/无人驾驶麻省理工01讲/TIM截图20181209135737.jpg" alt=""><br><a href="http://www.365yg.com/i6632863427394011652/#mid=1619346472494083" target="_blank" rel="noopener">奖励游戏</a></p><h1 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h1><p>可能本文有很多童鞋会访问不了其中的一些网页，那么我就放出福利吧<br><a href="https://github.com/Alvin9999/new-pac/wiki/ss%E5%85%8D%E8%B4%B9%E8%B4%A6%E5%8F%B7" target="_blank" rel="noopener">GitHub福利链接</a><br><a href="https://doub.io/sszhfx/" target="_blank" rel="noopener">免费ssr账号</a></p>]]></content>
      
      
      
    </entry>
    
    <entry>
      <title>无人驾驶麻省理工02讲</title>
      <link href="/2018/12/09/%E6%97%A0%E4%BA%BA%E9%A9%BE%E9%A9%B6%E9%BA%BB%E7%9C%81%E7%90%86%E5%B7%A502%E8%AE%B2/"/>
      <url>/2018/12/09/%E6%97%A0%E4%BA%BA%E9%A9%BE%E9%A9%B6%E9%BA%BB%E7%9C%81%E7%90%86%E5%B7%A502%E8%AE%B2/</url>
      
        <content type="html"><![CDATA[<p>相关资料打包链接: <a href="https://whuteducn-my.sharepoint.com/:f:/g/personal/220077_whut_edu_cn/ErQbTLrw69xLr7uSGoyKLfcB0wnatT99IWidnrhy7elCHA?e=JuGaNq" target="_blank" rel="noopener">麻省理工自动驾驶 MIT 6.S094第二讲</a><br>bilibili: <a href="https://www.bilibili.com/video/av23594594/?p=2" target="_blank" rel="noopener">麻省理工自动驾驶 MIT 6.S094第二讲</a></p><h1 id="写在前言：上一篇介绍了无人驾驶和深度学习的心得，这一篇我想和大家分享一下自动驾驶的心得。"><a href="#写在前言：上一篇介绍了无人驾驶和深度学习的心得，这一篇我想和大家分享一下自动驾驶的心得。" class="headerlink" title="写在前言：上一篇介绍了无人驾驶和深度学习的心得，这一篇我想和大家分享一下自动驾驶的心得。"></a>写在前言：上一篇介绍了无人驾驶和深度学习的心得，这一篇我想和大家分享一下自动驾驶的心得。</h1><h2 id="不同的自主驾驶方法"><a href="#不同的自主驾驶方法" class="headerlink" title="不同的自主驾驶方法"></a>不同的自主驾驶方法</h2><h3 id="P8、P9、P10、P11，两种人工智能策略"><a href="#P8、P9、P10、P11，两种人工智能策略" class="headerlink" title="P8、P9、P10、P11，两种人工智能策略"></a>P8、P9、P10、P11，两种人工智能策略</h3><p>以人为中心的自动驾驶和以AI系统为中心的自动驾驶，简单点就是说谁对驾驶主要负责。</p><h3 id="P14无人驾驶的社会期望"><a href="#P14无人驾驶的社会期望" class="headerlink" title="P14无人驾驶的社会期望"></a>P14无人驾驶的社会期望</h3><p>这个视频没有找到，但是我感觉这种有点科幻了。。。</p><h3 id="P17软件系统框架图"><a href="#P17软件系统框架图" class="headerlink" title="P17软件系统框架图"></a>P17软件系统框架图</h3><p><img src="/2018/12/09/无人驾驶麻省理工02讲/图片01.jpg" alt=""></p><p>很好的一个软件系统解说图。</p><h3 id="P29不同场景的驾驶策略"><a href="#P29不同场景的驾驶策略" class="headerlink" title="P29不同场景的驾驶策略"></a>P29不同场景的驾驶策略</h3><p>第一种我理解的是那种AI辅助决策的，无人驾驶系统提供决方案供驾驶人员选择，是以驾驶人员的判断为决策中心；第二种AI则是完全AI决策，这个时候的AI系统不仅仅能够找到解决方案，还能够自主的解决问题。但是对也这两套系统，我觉得还是从安全的角度划分一下决策权限好一点，明显经验丰富的驾驶人员应该为最高权限，我还是不太愿意把自己的生命完全托付给AI。比较有意思的是，AI的决策时间远远小于人类的判断时间，或者说在做出理性决策的时间上，人类需要的时间会大于AI的决策时间，这个感觉可以给予AI系统一些比较确定或者通用的高级权限（如碰到行人或安全栏紧急刹车），从而达到及时保护驾驶人员的安全。另外，无人驾驶准确率不需要达到100%，在极端情况下将控制权转交给驾驶人员。</p><h2 id="传感器"><a href="#传感器" class="headerlink" title="传感器"></a>传感器</h2><p>普通雷达传感器便宜稳定，但是成像效果差；激光雷达成本高，但是成像效果好；照相机局限于光源良好的环境。</p><h2 id="无人驾驶商业公司产品"><a href="#无人驾驶商业公司产品" class="headerlink" title="无人驾驶商业公司产品"></a>无人驾驶商业公司产品</h2><p>Waymo、Uber、Tesla、Audi A8</p><h2 id="人工智能和深度学习的应用场景"><a href="#人工智能和深度学习的应用场景" class="headerlink" title="人工智能和深度学习的应用场景"></a>人工智能和深度学习的应用场景</h2><h3 id="P54动态识别"><a href="#P54动态识别" class="headerlink" title="P54动态识别"></a>P54动态识别</h3><p>此处应献上GitHub代码链接，嗯，找个时间复现一下。</p><p><a href="https://github.com/raulmur/ORB_SLAM2" target="_blank" rel="noopener">GitHub直达链接</a></p><h3 id="P57DeepVO演示"><a href="#P57DeepVO演示" class="headerlink" title="P57DeepVO演示"></a>P57DeepVO演示</h3><p>这个感兴趣的小伙伴可以在资料包里找到，我已经从国外搬运过来了。</p><h3 id="P73、P74、P75极端交通情况的决策"><a href="#P73、P74、P75极端交通情况的决策" class="headerlink" title="P73、P74、P75极端交通情况的决策"></a>P73、P74、P75极端交通情况的决策</h3><p>这个选取了三个典型的交通状况，主要是考验AI系统对于安全策略的一个度量，如何规避危险交通行为、危险交通行为发生时应该采取何种策略、如何取得最佳行为策略等。</p>]]></content>
      
      
      
    </entry>
    
    <entry>
      <title>水下机器人研究01</title>
      <link href="/2018/12/09/%E6%B0%B4%E4%B8%8B%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%A0%94%E7%A9%B601/"/>
      <url>/2018/12/09/%E6%B0%B4%E4%B8%8B%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%A0%94%E7%A9%B601/</url>
      
        <content type="html"><![CDATA[<h1 id="水下机器人的运动分析与建模"><a href="#水下机器人的运动分析与建模" class="headerlink" title="水下机器人的运动分析与建模"></a>水下机器人的运动分析与建模</h1><p>先放出框架图</p><p><img src="/2018/12/09/水下机器人研究01/水下机器人的运动分析与建模.png" alt=""></p><p>对于水下机器人，一定要建立一个静止的坐标系（定系）和运动的坐标系（动系），这个是分析水下机器人的运动基础。</p><p>定系：越简单越好，一般建议起始点为静系，且水平面+重力坐标系为宜。</p><p>动系：水下机器人自身的坐标系，这个一般都是输入控制量给定的，而且对于某个时刻的水下机器人，相对定系的空间状态量是已知的，否则只能重新初始化为水平面+重力坐标系。</p><p>总结一下：</p><p><img src="/2018/12/09/水下机器人研究01/公式01.jpg" alt=""></p><h2 id="1、运动的分解和合成"><a href="#1、运动的分解和合成" class="headerlink" title="1、运动的分解和合成"></a>1、运动的分解和合成</h2><p>观察选择以速度作为表述，输入选择以角速度作为表述。</p><h2 id="2、力的分解和合成"><a href="#2、力的分解和合成" class="headerlink" title="2、力的分解和合成"></a>2、力的分解和合成</h2><p>涉及到流体的力学分析很麻烦，所以在只能选择低速状态下，这样就可以考虑流体力学的一阶泰勒展开式，对于高阶的受力可以忽略不计。</p><h2 id="3、力矩问题"><a href="#3、力矩问题" class="headerlink" title="3、力矩问题"></a>3、力矩问题</h2><p>在输入设定的时候，通过设定的扭矩来达到相应运动变化，即受力平衡状况调节。</p>]]></content>
      
      
      
    </entry>
    
  
  
</search>
